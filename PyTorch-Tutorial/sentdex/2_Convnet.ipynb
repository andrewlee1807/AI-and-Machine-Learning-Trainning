{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import shutil\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class DogsVSCats:\n",
    "    IMG_SIZE = 50\n",
    "    ROOT = 'PetImages'\n",
    "    CATS = \"Cat\"\n",
    "    DOGS = \"Dog\"\n",
    "    TESTING = ROOT + \"/test\"\n",
    "    TRAIN = ROOT + \"/train\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data_loaders = None\n",
    "\n",
    "    @classmethod\n",
    "    def structure_dataset(cls):\n",
    "        datasets_img_name = {cls.CATS: [], cls.DOGS: []}\n",
    "        for label in cls.LABELS:\n",
    "            sub_folder = cls.ROOT + '/' + label\n",
    "            for f in tqdm(os.listdir(sub_folder)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        # path = os.path.join(sub_folder, f)\n",
    "                        datasets_img_name[label].append(f)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "        test_account_for = 0.2\n",
    "        # train_set =\n",
    "        #  Copy folder:\n",
    "        for dtype in [cls.DOGS, cls.CATS]:\n",
    "            img_names = datasets_img_name[dtype]\n",
    "            for dset in [cls.TRAIN, cls.TESTING]:\n",
    "                source = cls.ROOT + '/' + label\n",
    "                dest = os.path.join(dset, dtype)\n",
    "                if dset == cls.TRAIN:\n",
    "                    loop_range = range(0, int(len(img_names) * (1 - test_account_for)))\n",
    "                else:\n",
    "                    loop_range = range(int(len(img_names) * (1 - test_account_for)), len(img_names))\n",
    "                for i in tqdm(loop_range):\n",
    "                    shutil.copyfile(source + '/' + img_names[i], dest + '/' + img_names[i])\n",
    "\n",
    "    @staticmethod\n",
    "    def train_val_dataset(dataset, val_split=0.2):\n",
    "        train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "        datasets = {'train': Subset(dataset, train_idx), 'val': Subset(dataset, val_idx)}\n",
    "        return datasets\n",
    "\n",
    "    def load_data_from_disk(self):\n",
    "        TRANSFORM_IMG = transforms.Compose([\n",
    "            transforms.Resize((50, 50)),\n",
    "            # transforms.CenterCrop(256),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            #                      std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        BATCH_SIZE = 32\n",
    "\n",
    "        train_data = torchvision.datasets.ImageFolder(root=self.TRAIN, transform=TRANSFORM_IMG)\n",
    "        test_data = torchvision.datasets.ImageFolder(root=self.TESTING, transform=TRANSFORM_IMG)\n",
    "\n",
    "        datasets = self.train_val_dataset(train_data)\n",
    "        self.data_loaders = {x: data.DataLoader(datasets[x], BATCH_SIZE, shuffle=True, num_workers=4) for x in\n",
    "                             ['train', 'val']}\n",
    "        self.data_loaders['test'] = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "        idx_to_class = {v: k for k, v in test_data.class_to_idx.items()}\n",
    "        print(idx_to_class)\n",
    "\n",
    "        # self.train_data_loader = data.DataLoader(self.train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "        # test_data_loader = data.DataLoader(self.test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# DogsVSCats.structure_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Cat', 1: 'Dog'}\n"
     ]
    }
   ],
   "source": [
    "cat_dog = DogsVSCats()\n",
    "cat_dog.load_data_from_disk()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'train': <torch.utils.data.dataloader.DataLoader at 0x1ec8266bfd0>,\n 'val': <torch.utils.data.dataloader.DataLoader at 0x1ec82631e20>,\n 'test': <torch.utils.data.dataloader.DataLoader at 0x1ec8266bbb0>}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dog.data_loaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "125\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "for x in ['train', 'val', 'test']:\n",
    "    print(len(cat_dog.data_loaders[x]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# need to flatten the output from the last convolutional layer before you can pass it through a regular \"dense\" layer (or what pytorch calls a linear layer)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)  # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64,\n",
    "                               5)  # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(3, 50, 50).view(-1, 3, 50, 50)\n",
    "        # x = torch.randn(50, 50).view(-1, 1, 50, 50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)  #flattening.\n",
    "        self.fc2 = nn.Linear(512, 2)  # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net().cuda()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5134, 0.4866]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 50, 50).cuda()\n",
    "net(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            2,432\n",
      "├─Conv2d: 1-2                            51,264\n",
      "├─Conv2d: 1-3                            204,928\n",
      "├─Linear: 1-4                            262,656\n",
      "├─Linear: 1-5                            1,026\n",
      "=================================================================\n",
      "Total params: 522,306\n",
      "Trainable params: 522,306\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\n├─Conv2d: 1-1                            2,432\n├─Conv2d: 1-2                            51,264\n├─Conv2d: 1-3                            204,928\n├─Linear: 1-4                            262,656\n├─Linear: 1-5                            1,026\n=================================================================\nTotal params: 522,306\nTrainable params: 522,306\nNon-trainable params: 0\n================================================================="
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 28.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.24629144370555878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Loss: 0.2468465268611908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 28.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2. Loss: 0.25217342376708984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:16<00:00, 31.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3. Loss: 0.2511371076107025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:16<00:00, 30.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4. Loss: 0.24790258705615997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:16<00:00, 30.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5. Loss: 0.25479811429977417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:14<00:00, 33.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6. Loss: 0.25439298152923584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:13<00:00, 35.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7. Loss: 0.24696531891822815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:14<00:00, 33.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8. Loss: 0.24926181137561798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:13<00:00, 37.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9. Loss: 0.2514626681804657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for inputs, labels in tqdm(cat_dog.data_loaders['train']):\n",
    "        net.zero_grad()\n",
    "        # print(inputs.size())\n",
    "        outputs = net(inputs.cuda())\n",
    "        # outputs = net(inputs.view(-1, 1, 50, 50))\n",
    "        # print(outputs.size())\n",
    "        loss = loss_function(outputs, torch.nn.functional.one_hot(labels).float().cuda())\n",
    "        # print(loss.item())\n",
    "        # loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  # Does the update\n",
    "    print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:07<00:00, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 2500\n",
      "Accuracy:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(cat_dog.data_loaders['test']):\n",
    "        outputs = net(inputs.cuda())\n",
    "        predicted_class = torch.argmax(outputs).cpu()\n",
    "        correct += (predicted_class == labels).sum().item()\n",
    "        total += len(labels)\n",
    "    print(total, correct)\n",
    "    print(\"Accuracy: \", correct/total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}